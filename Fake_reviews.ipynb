{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (1.2.5)\n",
      "Requirement already satisfied: graphviz in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (from catboost) (3.9.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (from catboost) (1.14.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (from catboost) (5.23.0)\n",
      "Requirement already satisfied: six in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (from matplotlib->catboost) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (from matplotlib->catboost) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (from matplotlib->catboost) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (from matplotlib->catboost) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (from matplotlib->catboost) (3.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\vaibhav\\.conda\\envs\\fakereviews\\lib\\site-packages (from plotly->catboost) (9.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Install catboost\n",
    "!pip3 install catboost\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('fake reviews dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I've had mine for a couple of years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and feel of this pillow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it is a great product for the price!  I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the set for two months now and have not been</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                                                                   text_  \n",
       "0            Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty  \n",
       "1       love it, a great upgrade from the original.  I've had mine for a couple of years  \n",
       "2                    This pillow saved my back. I love the look and feel of this pillow.  \n",
       "3      Missing information on how to use it, but it is a great product for the price!  I  \n",
       "4  Very nice set. Good quality. We have had the set for two months now and have not been  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "CG    20216\n",
       "OR    20216\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_'] = df['text_'].str.replace('\\n', ' ')\n",
    "df['target'] = np.where(df['label']=='CG', 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    20216\n",
       "0    20216\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_to_features(df, column):\n",
    "    \"\"\"Identify punctuation within a column and convert to a text representation.\n",
    "    \n",
    "    Args:\n",
    "        df (object): Pandas dataframe.\n",
    "        column (string): Name of column containing text. \n",
    "        \n",
    "    Returns:\n",
    "        df[column]: Original column with punctuation converted to text, \n",
    "                    i.e. \"Wow! > \"Wow exclamation\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df[column] = df[column].replace('!', ' exclamation ')\n",
    "    df[column] = df[column].replace('?', ' question ')\n",
    "    df[column] = df[column].replace('\\'', ' quotation ')\n",
    "    df[column] = df[column].replace('\\\"', ' quotation ')\n",
    "    \n",
    "    return df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Vaibhav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "df['text_'] = punctuation_to_features(df, 'text_')\n",
    "nltk.download('punkt');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(column):\n",
    "   \n",
    "    \n",
    "    tokens = nltk.word_tokenize(column)\n",
    "    return [w for w in tokens if w.isalpha()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty</td>\n",
       "      <td>1</td>\n",
       "      <td>[Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I've had mine for a couple of years</td>\n",
       "      <td>1</td>\n",
       "      <td>[love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and feel of this pillow.</td>\n",
       "      <td>1</td>\n",
       "      <td>[This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it is a great product for the price!  I</td>\n",
       "      <td>1</td>\n",
       "      <td>[Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the set for two months now and have not been</td>\n",
       "      <td>1</td>\n",
       "      <td>[Very, nice, set, Good, quality, We, have, had, the, set, for, two, months, now, and, have, not, been]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I WANTED DIFFERENT FLAVORS BUT THEY ARE NOT.</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, WANTED, DIFFERENT, FLAVORS, BUT, THEY, ARE, NOT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>They are the perfect touch for me and the only thing I wish they had a little more space.</td>\n",
       "      <td>1</td>\n",
       "      <td>[They, are, the, perfect, touch, for, me, and, the, only, thing, I, wish, they, had, a, little, more, space]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>These done fit well and look great.  I love the smoothness of the edges and the extra</td>\n",
       "      <td>1</td>\n",
       "      <td>[These, done, fit, well, and, look, great, I, love, the, smoothness, of, the, edges, and, the, extra]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Great big numbers &amp; easy to read, the only thing I didn't like is the size of the</td>\n",
       "      <td>1</td>\n",
       "      <td>[Great, big, numbers, easy, to, read, the, only, thing, I, did, like, is, the, size, of, the]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>My son loves this comforter and it is very well made.  We also have a baby</td>\n",
       "      <td>1</td>\n",
       "      <td>[My, son, loves, this, comforter, and, it, is, very, well, made, We, also, have, a, baby]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "5  Home_and_Kitchen_5     3.0    CG   \n",
       "6  Home_and_Kitchen_5     5.0    CG   \n",
       "7  Home_and_Kitchen_5     3.0    CG   \n",
       "8  Home_and_Kitchen_5     5.0    CG   \n",
       "9  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                                                                       text_  \\\n",
       "0                Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty   \n",
       "1           love it, a great upgrade from the original.  I've had mine for a couple of years   \n",
       "2                        This pillow saved my back. I love the look and feel of this pillow.   \n",
       "3          Missing information on how to use it, but it is a great product for the price!  I   \n",
       "4      Very nice set. Good quality. We have had the set for two months now and have not been   \n",
       "5                                               I WANTED DIFFERENT FLAVORS BUT THEY ARE NOT.   \n",
       "6  They are the perfect touch for me and the only thing I wish they had a little more space.   \n",
       "7      These done fit well and look great.  I love the smoothness of the edges and the extra   \n",
       "8          Great big numbers & easy to read, the only thing I didn't like is the size of the   \n",
       "9                 My son loves this comforter and it is very well made.  We also have a baby   \n",
       "\n",
       "   target  \\\n",
       "0       1   \n",
       "1       1   \n",
       "2       1   \n",
       "3       1   \n",
       "4       1   \n",
       "5       1   \n",
       "6       1   \n",
       "7       1   \n",
       "8       1   \n",
       "9       1   \n",
       "\n",
       "                                                                                                      tokenized  \n",
       "0                           [Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]  \n",
       "1                   [love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]  \n",
       "2                              [This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]  \n",
       "3              [Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]  \n",
       "4        [Very, nice, set, Good, quality, We, have, had, the, set, for, two, months, now, and, have, not, been]  \n",
       "5                                                          [I, WANTED, DIFFERENT, FLAVORS, BUT, THEY, ARE, NOT]  \n",
       "6  [They, are, the, perfect, touch, for, me, and, the, only, thing, I, wish, they, had, a, little, more, space]  \n",
       "7         [These, done, fit, well, and, look, great, I, love, the, smoothness, of, the, edges, and, the, extra]  \n",
       "8                 [Great, big, numbers, easy, to, read, the, only, thing, I, did, like, is, the, size, of, the]  \n",
       "9                     [My, son, loves, this, comforter, and, it, is, very, well, made, We, also, have, a, baby]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['tokenized'] = df.apply(lambda x: tokenize(x['text_']), axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vaibhav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokenized_column):\n",
    "    \n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    return [word for word in tokenized_column if not word in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stopwords_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty</td>\n",
       "      <td>1</td>\n",
       "      <td>[Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]</td>\n",
       "      <td>[Love, Well, made, sturdy, comfortable, I, love, Very, pretty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I've had mine for a couple of years</td>\n",
       "      <td>1</td>\n",
       "      <td>[love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]</td>\n",
       "      <td>[love, great, upgrade, original, I, mine, couple, years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and feel of this pillow.</td>\n",
       "      <td>1</td>\n",
       "      <td>[This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]</td>\n",
       "      <td>[This, pillow, saved, back, I, love, look, feel, pillow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it is a great product for the price!  I</td>\n",
       "      <td>1</td>\n",
       "      <td>[Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]</td>\n",
       "      <td>[Missing, information, use, great, product, price, I]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the set for two months now and have not been</td>\n",
       "      <td>1</td>\n",
       "      <td>[Very, nice, set, Good, quality, We, have, had, the, set, for, two, months, now, and, have, not, been]</td>\n",
       "      <td>[Very, nice, set, Good, quality, We, set, two, months]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I WANTED DIFFERENT FLAVORS BUT THEY ARE NOT.</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, WANTED, DIFFERENT, FLAVORS, BUT, THEY, ARE, NOT]</td>\n",
       "      <td>[I, WANTED, DIFFERENT, FLAVORS, BUT, THEY, ARE, NOT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>They are the perfect touch for me and the only thing I wish they had a little more space.</td>\n",
       "      <td>1</td>\n",
       "      <td>[They, are, the, perfect, touch, for, me, and, the, only, thing, I, wish, they, had, a, little, more, space]</td>\n",
       "      <td>[They, perfect, touch, thing, I, wish, little, space]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>These done fit well and look great.  I love the smoothness of the edges and the extra</td>\n",
       "      <td>1</td>\n",
       "      <td>[These, done, fit, well, and, look, great, I, love, the, smoothness, of, the, edges, and, the, extra]</td>\n",
       "      <td>[These, done, fit, well, look, great, I, love, smoothness, edges, extra]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Great big numbers &amp; easy to read, the only thing I didn't like is the size of the</td>\n",
       "      <td>1</td>\n",
       "      <td>[Great, big, numbers, easy, to, read, the, only, thing, I, did, like, is, the, size, of, the]</td>\n",
       "      <td>[Great, big, numbers, easy, read, thing, I, like, size]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>My son loves this comforter and it is very well made.  We also have a baby</td>\n",
       "      <td>1</td>\n",
       "      <td>[My, son, loves, this, comforter, and, it, is, very, well, made, We, also, have, a, baby]</td>\n",
       "      <td>[My, son, loves, comforter, well, made, We, also, baby]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "5  Home_and_Kitchen_5     3.0    CG   \n",
       "6  Home_and_Kitchen_5     5.0    CG   \n",
       "7  Home_and_Kitchen_5     3.0    CG   \n",
       "8  Home_and_Kitchen_5     5.0    CG   \n",
       "9  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                                                                       text_  \\\n",
       "0                Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty   \n",
       "1           love it, a great upgrade from the original.  I've had mine for a couple of years   \n",
       "2                        This pillow saved my back. I love the look and feel of this pillow.   \n",
       "3          Missing information on how to use it, but it is a great product for the price!  I   \n",
       "4      Very nice set. Good quality. We have had the set for two months now and have not been   \n",
       "5                                               I WANTED DIFFERENT FLAVORS BUT THEY ARE NOT.   \n",
       "6  They are the perfect touch for me and the only thing I wish they had a little more space.   \n",
       "7      These done fit well and look great.  I love the smoothness of the edges and the extra   \n",
       "8          Great big numbers & easy to read, the only thing I didn't like is the size of the   \n",
       "9                 My son loves this comforter and it is very well made.  We also have a baby   \n",
       "\n",
       "   target  \\\n",
       "0       1   \n",
       "1       1   \n",
       "2       1   \n",
       "3       1   \n",
       "4       1   \n",
       "5       1   \n",
       "6       1   \n",
       "7       1   \n",
       "8       1   \n",
       "9       1   \n",
       "\n",
       "                                                                                                      tokenized  \\\n",
       "0                           [Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]   \n",
       "1                   [love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]   \n",
       "2                              [This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]   \n",
       "3              [Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]   \n",
       "4        [Very, nice, set, Good, quality, We, have, had, the, set, for, two, months, now, and, have, not, been]   \n",
       "5                                                          [I, WANTED, DIFFERENT, FLAVORS, BUT, THEY, ARE, NOT]   \n",
       "6  [They, are, the, perfect, touch, for, me, and, the, only, thing, I, wish, they, had, a, little, more, space]   \n",
       "7         [These, done, fit, well, and, look, great, I, love, the, smoothness, of, the, edges, and, the, extra]   \n",
       "8                 [Great, big, numbers, easy, to, read, the, only, thing, I, did, like, is, the, size, of, the]   \n",
       "9                     [My, son, loves, this, comforter, and, it, is, very, well, made, We, also, have, a, baby]   \n",
       "\n",
       "                                                          stopwords_removed  \n",
       "0            [Love, Well, made, sturdy, comfortable, I, love, Very, pretty]  \n",
       "1                  [love, great, upgrade, original, I, mine, couple, years]  \n",
       "2                  [This, pillow, saved, back, I, love, look, feel, pillow]  \n",
       "3                     [Missing, information, use, great, product, price, I]  \n",
       "4                    [Very, nice, set, Good, quality, We, set, two, months]  \n",
       "5                      [I, WANTED, DIFFERENT, FLAVORS, BUT, THEY, ARE, NOT]  \n",
       "6                     [They, perfect, touch, thing, I, wish, little, space]  \n",
       "7  [These, done, fit, well, look, great, I, love, smoothness, edges, extra]  \n",
       "8                   [Great, big, numbers, easy, read, thing, I, like, size]  \n",
       "9                   [My, son, loves, comforter, well, made, We, also, baby]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['stopwords_removed'] = df.apply(lambda x: remove_stopwords(x['tokenized']), axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming(tokenized_column):\n",
    "    \n",
    "    \n",
    "    stemmer = PorterStemmer() \n",
    "    return [stemmer.stem(word).lower() for word in tokenized_column]\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>porter_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty</td>\n",
       "      <td>1</td>\n",
       "      <td>[Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]</td>\n",
       "      <td>[Love, Well, made, sturdy, comfortable, I, love, Very, pretty]</td>\n",
       "      <td>[love, well, made, sturdi, comfort, i, love, veri, pretti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I've had mine for a couple of years</td>\n",
       "      <td>1</td>\n",
       "      <td>[love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]</td>\n",
       "      <td>[love, great, upgrade, original, I, mine, couple, years]</td>\n",
       "      <td>[love, great, upgrad, origin, i, mine, coupl, year]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and feel of this pillow.</td>\n",
       "      <td>1</td>\n",
       "      <td>[This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]</td>\n",
       "      <td>[This, pillow, saved, back, I, love, look, feel, pillow]</td>\n",
       "      <td>[thi, pillow, save, back, i, love, look, feel, pillow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it is a great product for the price!  I</td>\n",
       "      <td>1</td>\n",
       "      <td>[Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]</td>\n",
       "      <td>[Missing, information, use, great, product, price, I]</td>\n",
       "      <td>[miss, inform, use, great, product, price, i]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the set for two months now and have not been</td>\n",
       "      <td>1</td>\n",
       "      <td>[Very, nice, set, Good, quality, We, have, had, the, set, for, two, months, now, and, have, not, been]</td>\n",
       "      <td>[Very, nice, set, Good, quality, We, set, two, months]</td>\n",
       "      <td>[veri, nice, set, good, qualiti, we, set, two, month]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I WANTED DIFFERENT FLAVORS BUT THEY ARE NOT.</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, WANTED, DIFFERENT, FLAVORS, BUT, THEY, ARE, NOT]</td>\n",
       "      <td>[I, WANTED, DIFFERENT, FLAVORS, BUT, THEY, ARE, NOT]</td>\n",
       "      <td>[i, want, differ, flavor, but, they, are, not]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>They are the perfect touch for me and the only thing I wish they had a little more space.</td>\n",
       "      <td>1</td>\n",
       "      <td>[They, are, the, perfect, touch, for, me, and, the, only, thing, I, wish, they, had, a, little, more, space]</td>\n",
       "      <td>[They, perfect, touch, thing, I, wish, little, space]</td>\n",
       "      <td>[they, perfect, touch, thing, i, wish, littl, space]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>These done fit well and look great.  I love the smoothness of the edges and the extra</td>\n",
       "      <td>1</td>\n",
       "      <td>[These, done, fit, well, and, look, great, I, love, the, smoothness, of, the, edges, and, the, extra]</td>\n",
       "      <td>[These, done, fit, well, look, great, I, love, smoothness, edges, extra]</td>\n",
       "      <td>[these, done, fit, well, look, great, i, love, smooth, edg, extra]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Great big numbers &amp; easy to read, the only thing I didn't like is the size of the</td>\n",
       "      <td>1</td>\n",
       "      <td>[Great, big, numbers, easy, to, read, the, only, thing, I, did, like, is, the, size, of, the]</td>\n",
       "      <td>[Great, big, numbers, easy, read, thing, I, like, size]</td>\n",
       "      <td>[great, big, number, easi, read, thing, i, like, size]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>My son loves this comforter and it is very well made.  We also have a baby</td>\n",
       "      <td>1</td>\n",
       "      <td>[My, son, loves, this, comforter, and, it, is, very, well, made, We, also, have, a, baby]</td>\n",
       "      <td>[My, son, loves, comforter, well, made, We, also, baby]</td>\n",
       "      <td>[my, son, love, comfort, well, made, we, also, babi]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "5  Home_and_Kitchen_5     3.0    CG   \n",
       "6  Home_and_Kitchen_5     5.0    CG   \n",
       "7  Home_and_Kitchen_5     3.0    CG   \n",
       "8  Home_and_Kitchen_5     5.0    CG   \n",
       "9  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                                                                       text_  \\\n",
       "0                Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty   \n",
       "1           love it, a great upgrade from the original.  I've had mine for a couple of years   \n",
       "2                        This pillow saved my back. I love the look and feel of this pillow.   \n",
       "3          Missing information on how to use it, but it is a great product for the price!  I   \n",
       "4      Very nice set. Good quality. We have had the set for two months now and have not been   \n",
       "5                                               I WANTED DIFFERENT FLAVORS BUT THEY ARE NOT.   \n",
       "6  They are the perfect touch for me and the only thing I wish they had a little more space.   \n",
       "7      These done fit well and look great.  I love the smoothness of the edges and the extra   \n",
       "8          Great big numbers & easy to read, the only thing I didn't like is the size of the   \n",
       "9                 My son loves this comforter and it is very well made.  We also have a baby   \n",
       "\n",
       "   target  \\\n",
       "0       1   \n",
       "1       1   \n",
       "2       1   \n",
       "3       1   \n",
       "4       1   \n",
       "5       1   \n",
       "6       1   \n",
       "7       1   \n",
       "8       1   \n",
       "9       1   \n",
       "\n",
       "                                                                                                      tokenized  \\\n",
       "0                           [Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]   \n",
       "1                   [love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]   \n",
       "2                              [This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]   \n",
       "3              [Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]   \n",
       "4        [Very, nice, set, Good, quality, We, have, had, the, set, for, two, months, now, and, have, not, been]   \n",
       "5                                                          [I, WANTED, DIFFERENT, FLAVORS, BUT, THEY, ARE, NOT]   \n",
       "6  [They, are, the, perfect, touch, for, me, and, the, only, thing, I, wish, they, had, a, little, more, space]   \n",
       "7         [These, done, fit, well, and, look, great, I, love, the, smoothness, of, the, edges, and, the, extra]   \n",
       "8                 [Great, big, numbers, easy, to, read, the, only, thing, I, did, like, is, the, size, of, the]   \n",
       "9                     [My, son, loves, this, comforter, and, it, is, very, well, made, We, also, have, a, baby]   \n",
       "\n",
       "                                                          stopwords_removed  \\\n",
       "0            [Love, Well, made, sturdy, comfortable, I, love, Very, pretty]   \n",
       "1                  [love, great, upgrade, original, I, mine, couple, years]   \n",
       "2                  [This, pillow, saved, back, I, love, look, feel, pillow]   \n",
       "3                     [Missing, information, use, great, product, price, I]   \n",
       "4                    [Very, nice, set, Good, quality, We, set, two, months]   \n",
       "5                      [I, WANTED, DIFFERENT, FLAVORS, BUT, THEY, ARE, NOT]   \n",
       "6                     [They, perfect, touch, thing, I, wish, little, space]   \n",
       "7  [These, done, fit, well, look, great, I, love, smoothness, edges, extra]   \n",
       "8                   [Great, big, numbers, easy, read, thing, I, like, size]   \n",
       "9                   [My, son, loves, comforter, well, made, We, also, baby]   \n",
       "\n",
       "                                                       porter_stemmed  \n",
       "0          [love, well, made, sturdi, comfort, i, love, veri, pretti]  \n",
       "1                 [love, great, upgrad, origin, i, mine, coupl, year]  \n",
       "2              [thi, pillow, save, back, i, love, look, feel, pillow]  \n",
       "3                       [miss, inform, use, great, product, price, i]  \n",
       "4               [veri, nice, set, good, qualiti, we, set, two, month]  \n",
       "5                      [i, want, differ, flavor, but, they, are, not]  \n",
       "6                [they, perfect, touch, thing, i, wish, littl, space]  \n",
       "7  [these, done, fit, well, look, great, i, love, smooth, edg, extra]  \n",
       "8              [great, big, number, easi, read, thing, i, like, size]  \n",
       "9                [my, son, love, comfort, well, made, we, also, babi]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['porter_stemmed'] = df.apply(lambda x: apply_stemming(x['stopwords_removed']), axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rejoin_words(tokenized_column):\n",
    "    return ( \" \".join(tokenized_column))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['all_text'] = df.apply(lambda x: rejoin_words(x['porter_stemmed']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love well made sturdi comfort i love veri pretti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love great upgrad origin i mine coupl year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thi pillow save back i love look feel pillow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>miss inform use great product price i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>veri nice set good qualiti we set two month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i want differ flavor but they are not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>they perfect touch thing i wish littl space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>these done fit well look great i love smooth edg extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>great big number easi read thing i like size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>my son love comfort well made we also babi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 all_text\n",
       "0        love well made sturdi comfort i love veri pretti\n",
       "1              love great upgrad origin i mine coupl year\n",
       "2            thi pillow save back i love look feel pillow\n",
       "3                   miss inform use great product price i\n",
       "4             veri nice set good qualiti we set two month\n",
       "5                   i want differ flavor but they are not\n",
       "6             they perfect touch thing i wish littl space\n",
       "7  these done fit well look great i love smooth edg extra\n",
       "8            great big number easi read thing i like size\n",
       "9              my son love comfort well made we also babi"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[['all_text']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf_vectorizer.fit_transform(df['all_text']).toarray()\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (32345, 5000)\n",
      "X_test shape: (8087, 5000)\n",
      "y_train shape: (32345,)\n",
      "y_test shape: (8087,)\n"
     ]
    }
   ],
   "source": [
    "# Display the shapes of the resulting arrays\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LinearSVC\": LinearSVC(),\n",
    "    \"XGBClassifier\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"LGBMClassifier\": LGBMClassifier(),\n",
    "    \"CatBoostClassifier\": CatBoostClassifier(silent=True),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "    \"BernoulliNB\": BernoulliNB(),\n",
    "    \"MultinomialNB\": MultinomialNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearSVC\n",
      "Accuracy: 0.875602819339681\n",
      "F1 Score: 0.8745948641236599\n",
      "ROC AUC Score: 0.8755886549601154\n",
      "Precision: 0.8756864702945582\n",
      "Recall: 0.8735059760956175\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      4071\n",
      "           1       0.88      0.87      0.87      4016\n",
      "\n",
      "    accuracy                           0.88      8087\n",
      "   macro avg       0.88      0.88      0.88      8087\n",
      "weighted avg       0.88      0.88      0.88      8087\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vaibhav\\.conda\\envs\\Fakereviews\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [04:18:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBClassifier\n",
      "Accuracy: 0.8530975639915914\n",
      "F1 Score: 0.8489318413021363\n",
      "ROC AUC Score: 0.8529494769631863\n",
      "Precision: 0.8674636174636174\n",
      "Recall: 0.8311752988047809\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86      4071\n",
      "           1       0.87      0.83      0.85      4016\n",
      "\n",
      "    accuracy                           0.85      8087\n",
      "   macro avg       0.85      0.85      0.85      8087\n",
      "weighted avg       0.85      0.85      0.85      8087\n",
      "\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 16200, number of negative: 16145\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.163391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174458\n",
      "[LightGBM] [Info] Number of data points in the train set: 32345, number of used features: 3234\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500850 -> initscore=0.003401\n",
      "[LightGBM] [Info] Start training from score 0.003401\n",
      "Model: LGBMClassifier\n",
      "Accuracy: 0.8524792877457648\n",
      "F1 Score: 0.8510425771007616\n",
      "ROC AUC Score: 0.8524531204584757\n",
      "Precision: 0.8534936138241923\n",
      "Recall: 0.848605577689243\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      4071\n",
      "           1       0.85      0.85      0.85      4016\n",
      "\n",
      "    accuracy                           0.85      8087\n",
      "   macro avg       0.85      0.85      0.85      8087\n",
      "weighted avg       0.85      0.85      0.85      8087\n",
      "\n",
      "--------------------------------------------------\n",
      "Model: CatBoostClassifier\n",
      "Accuracy: 0.8654630889081242\n",
      "F1 Score: 0.8627994955863808\n",
      "ROC AUC Score: 0.8653710813831385\n",
      "Precision: 0.8740419008686765\n",
      "Recall: 0.8518426294820717\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4071\n",
      "           1       0.87      0.85      0.86      4016\n",
      "\n",
      "    accuracy                           0.87      8087\n",
      "   macro avg       0.87      0.87      0.87      8087\n",
      "weighted avg       0.87      0.87      0.87      8087\n",
      "\n",
      "--------------------------------------------------\n",
      "Model: KNeighborsClassifier\n",
      "Accuracy: 0.585631260046989\n",
      "F1 Score: 0.6990570273911091\n",
      "ROC AUC Score: 0.5882217873776328\n",
      "Precision: 0.5467059980334317\n",
      "Recall: 0.9691235059760956\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.21      0.33      4071\n",
      "           1       0.55      0.97      0.70      4016\n",
      "\n",
      "    accuracy                           0.59      8087\n",
      "   macro avg       0.71      0.59      0.52      8087\n",
      "weighted avg       0.71      0.59      0.52      8087\n",
      "\n",
      "--------------------------------------------------\n",
      "Model: DecisionTreeClassifier\n",
      "Accuracy: 0.7613453691109188\n",
      "F1 Score: 0.7616695480365522\n",
      "ROC AUC Score: 0.7613898373589895\n",
      "Precision: 0.7555120039196472\n",
      "Recall: 0.7679282868525896\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76      4071\n",
      "           1       0.76      0.77      0.76      4016\n",
      "\n",
      "    accuracy                           0.76      8087\n",
      "   macro avg       0.76      0.76      0.76      8087\n",
      "weighted avg       0.76      0.76      0.76      8087\n",
      "\n",
      "--------------------------------------------------\n",
      "Model: RandomForestClassifier\n",
      "Accuracy: 0.8622480524298256\n",
      "F1 Score: 0.8651005085977235\n",
      "ROC AUC Score: 0.8624317517451686\n",
      "Precision: 0.8420556341348421\n",
      "Recall: 0.8894422310756972\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      4071\n",
      "           1       0.84      0.89      0.87      4016\n",
      "\n",
      "    accuracy                           0.86      8087\n",
      "   macro avg       0.86      0.86      0.86      8087\n",
      "weighted avg       0.86      0.86      0.86      8087\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vaibhav\\.conda\\envs\\Fakereviews\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AdaBoostClassifier\n",
      "Accuracy: 0.7810065537282057\n",
      "F1 Score: 0.7775405099861826\n",
      "ROC AUC Score: 0.7809367112733052\n",
      "Precision: 0.7845373891001267\n",
      "Recall: 0.7706673306772909\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78      4071\n",
      "           1       0.78      0.77      0.78      4016\n",
      "\n",
      "    accuracy                           0.78      8087\n",
      "   macro avg       0.78      0.78      0.78      8087\n",
      "weighted avg       0.78      0.78      0.78      8087\n",
      "\n",
      "--------------------------------------------------\n",
      "Model: BernoulliNB\n",
      "Accuracy: 0.744404599975269\n",
      "F1 Score: 0.7829465504567888\n",
      "ROC AUC Score: 0.7456467424333617\n",
      "Precision: 0.6769566006900308\n",
      "Recall: 0.9282868525896414\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.56      0.69      4071\n",
      "           1       0.68      0.93      0.78      4016\n",
      "\n",
      "    accuracy                           0.74      8087\n",
      "   macro avg       0.78      0.75      0.74      8087\n",
      "weighted avg       0.78      0.74      0.74      8087\n",
      "\n",
      "--------------------------------------------------\n",
      "Model: MultinomialNB\n",
      "Accuracy: 0.8445653517991839\n",
      "F1 Score: 0.849009009009009\n",
      "ROC AUC Score: 0.844804581722239\n",
      "Precision: 0.8201438848920863\n",
      "Recall: 0.8799800796812749\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      4071\n",
      "           1       0.82      0.88      0.85      4016\n",
      "\n",
      "    accuracy                           0.84      8087\n",
      "   macro avg       0.85      0.84      0.84      8087\n",
      "weighted avg       0.85      0.84      0.84      8087\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"ROC AUC Score: {roc_auc}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: LinearSVC\n",
      "Accuracy: 0.875602819339681\n",
      "F1 Score: 0.8745948641236599\n",
      "ROC AUC Score: 0.8755886549601154\n",
      "Precision: 0.8756864702945582\n",
      "Recall: 0.8735059760956175\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      4071\n",
      "           1       0.88      0.87      0.87      4016\n",
      "\n",
      "    accuracy                           0.88      8087\n",
      "   macro avg       0.88      0.88      0.88      8087\n",
      "weighted avg       0.88      0.88      0.88      8087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, classification_report\n",
    "\n",
    "# Initialize and train the LinearSVC model\n",
    "best_model = LinearSVC()\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate and print metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Model: LinearSVC\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(best_model, 'linear_svc_model.pkl')\n",
    "# Save the vectorizer\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fakereviews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
